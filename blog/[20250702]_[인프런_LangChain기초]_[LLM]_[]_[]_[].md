# Langchain 기초입니다.

실습 파일 : https://github.com/tsdata/langchain-study  

* 기본 체인 (Prompt + LLM)
사용자의 입력(프롬프트)을 받아 LLM을 통해 적절한 응답이나 결과를 생성하는 구조

## 1. 기본 체인의 구성 요소
1. __프롬프트(Prompt)__: 사용자 또는 시스템에서 LLM에게 작업 수행을 요청하는 지시문
2. __LLM(Large Language Model)__: 대규모 언어 모델로, 다량의 텍스트 데이터에서 학습하여 언어를 이해하고 생성할 수 있는 인공지능 시스템. GPT, Gemini 등이 있으며 프롬프트 바탕으로 응답을 생성

## 2. 일반적인 작동 방식
1. 프롬프트 생성
2. LLM 처리
3. 응답 반환

__PromptTemplate__
* PromptTemplate + LLMs(단일 문장 입력 -> 단일 문장 출력)
* 문자열 프롬프트를 위한 템플릿 생성. Python의 문자열 포맷팅 구문 사용
* 내용: 지시사항, 몇 가지 예시, 특정 맥락 및 질문 등

## 3. 챗 프롬프트 템플릿
1. Message 유형
* SystemMessage : 시스템 기능 설명
* HumanMessage : 사용자의 질문 나타냄
* AIMessage : AI 모델의 응답 제공
* FunctionMessage : 특정 함수 호출의 결과 나타냄
* ToolMessage : 도구 호출의 결과 나타냄  

- ChatPromptTemplates + ChatModels(여러 메시지 입력 -> 단일 메시지 출력)
- 채팅 메시지를 원소로 갖는 리스트 형태
- 구성 : 각 채팅 메시지는 역할과 내용이 짝을 이루는 형태

## 4. LangChain 모델 유형
LLM과 Chat Model 클래스는 각각 다른 형태의 입력과 출력을 다루는 언어 모델  
일반적으로 LLM은 주로 단일 요청에 대한 복잡한 출력을 생성하는 데 적합한 반면, Chat Model은 사용자와의 상호작용을 통한 연속적인 대화 관리에 더 적합함.

__LLM__
* 기능 : 텍스트 문자열을 입력받아 처리한 후, 텍스트 문자열 반환. 광범위한 언어 이해 및 텍스트 작성 작업에 사용됨.  
ex. 문서 요약, 콘텐츠 생성 등

__ Chat Model__
* 기능 : 메시지의 리스트를 입력으로 받고, 하나의 메시지 반환함. 대화형 상황에 최적화되어 있으며, 사용자와의 연속적인 대화를 처리하는 데 사용. 맥락을 유지하면서 적절한 응답을 생성하는 데 중점을 둠

## 5. Langchain의 LLM 모델 파라미터 설정
* Temperature : 생성된 텍스트의 다양성 조정. 값이 작으면 예측 가능하고 일관된 출력을 생성하는 반면, 값이 크면 다양하고 예측하기 어려운 출력 생성
* Max Tokens(최대 토큰 수) : 생성할 최대 토큰 수 지정함. 생성할 텍스트의 길이 제한
* Top P(Top Probability) : 생성 과정에서 특정 확률 분포 내에서 상위 P% 토큰만을 고려
* Frequency Penalty(존재 패널티) : 텍스트 내에서 단어의 존재 유무에 따라 그 단어의 선택 확률을 조정함. 값이 클수록 아직 텍스트에 등장하지 않은 새로운 단어의 사용이 장려됨(0~1)
* Stop Sequences(정지 시퀀스) : 특정 단어나 구절이 등장할 경우 생성을 멈추도록 설정함. 이는 출력을 특정 포인트에서 종료하고자 할 때 사용


